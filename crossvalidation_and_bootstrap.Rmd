---
title: "Cross Validation and Bootstrap"
author: "Ozan Aygun"
date: "6/18/2017"
output: 
   html_document:
        toc: true
        number_sections: true
        depth: 4
        theme: cerulean
        highlight: tango
        df_print: paged
---

# Introduction

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,results = "markup", fig.align = "center", fig.width = 5, fig.height = 4,message=FALSE,warning=FALSE)
```

**Here our goal is to study resampling methods Cross Validation and Bootstrap.** 

___

# Cross-Validation

## Leave-one-out Cross Validation (LOOCV)

```{r}
require(ISLR); require(boot)
```

We will ise **cv.glm** function from boot package. This function calculates the estimated K-fold cross-validation prediction error for generalized linear models.

**Usage:**

**cv.glm(data, glmfit, cost, K)**

- **data:** matrix or data.frame containing the data. The rows should be cases and the columns correspond to variables, one of which is the response.

- **glmfit:** An object of class "glm" containing the results of a generalized linear model fitted to data.

- **cost:** A function of two vector arguments specifying the **cost function for the cross-validation.** The first argument to cost should correspond to the observed responses and the second argument should correspond to the predicted or fitted responses from the generalized linear model. cost must return a non-negative scalar value. **The default is the average squared error function.**

- **K:** The number of groups into which the data should be split to estimate the cross-validation prediction error. The value of K must be such that all groups are of approximately equal size. If the supplied value of K does not satisfy this criterion then it will be set to the closest integer which does and a warning is generated specifying the value of K used. **The default is to set K equal to the number of observations in data which gives the usual leave-one-out cross-validation.**

**Mechanism under the hood:**

The data is divided randomly into K groups. For each group the generalized linear model is fit to data omitting that group, then the function cost is applied to the observed responses in the group that was omitted from the fit and the prediction made by the fitted models for those 

When K is the number of observations leave-one-out cross-validation is used and all the possible splits of the data are used. When K is less than the number of observations the K splits to be used are found by randomly partitioning the data into K groups of approximately equal size. 

**Value:**

The returned value is a list with the following components.

- call: The original call to cv.glm.
- K: The value of K used for the K-fold cross validation.
- delta: A vector of length two. The first component is the raw cross-validation estimate of prediction error. The second component is the adjusted cross-validation estimate. The adjustment is designed to compensate for the bias introduced by not using leave-one-out cross-validation.
- seed:	The value of .Random.seed when cv.glm was called.

We will use the Auto data set from ISLR package:

```{r}
plot(mpg ~ horsepower, data = Auto, pch = 19, col = "navy" )
```

As we expected, there is a decrease in mpg with increased horsepower.

If we don't specify any family to glm, by default it fits a linear model:

```{r}
glm.fit = glm(mpg ~ horsepower, data = Auto)
cv.glm(Auto, glmfit = glm.fit)$delta
```

We get the estimated CV MSE and adjusted (bias-corrected version) CV MSE using our linear model that is fitted for the relationship between mpg (outcome) and horsepower (predictor).

Let's increase the model complexity and perform cross validation again. We recall that the relationship between the predictor and the outcome looks quite non-linear. Therefore, we will try adding polynomial terms and this will increase model complexity:

```{r}
cv.error = NULL
degree = 1:5 # we test up to 5th degree polynomial
for(d in degree){
  #For each degree of polynomial, fit a new model
  glm.fit = glm(mpg ~ poly(horsepower, degree = d), data = Auto) 
  # Calculate the LOOCV error for each model fit
  cv.error[d] = cv.glm(Auto, glm.fit)$delta[2]
}
plot(degree, cv.error, type = "b", col= "navy", pch = 20 )
```

As we can notice, addition of a second degree polynomial redices the CV error, and adding further terms do not seem to influence the error level.

## K- fold cross-validation

Let's try a 10-fold CV for the same problem. Note that in this case it is less work for the cv.glm function, because the model needs to be only fitted 10 times.

```{r}
cv.error10 = NULL
degree = 1:5 # we test up to 5th degree polynomial
for(d in degree){
  #For each degree of polynomial, fit a new model
  glm.fit = glm(mpg ~ poly(horsepower, degree = d), data = Auto) 
  # Calculate the LOOCV error for each model fit
  cv.error10[d] = cv.glm(Auto, glm.fit, K = 10)$delta[2]
}

plot(degree, cv.error10, type = "b", col= "red" )
```

In this example, LOOCV and 10-fold CV gave us pretty much the same answer. Howeer, in most cases we favor a 10-fold CV because it provides us a more stable estimate of error and it is also much cheaper to compute.

# Bootstrap


